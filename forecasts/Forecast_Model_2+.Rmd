---
title: "Forecast_Additional_Models"
author: "Justin Maynard"
date: "2025-03-31"
output: pdf_document
always_allow_html: true
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

## Setting R code chunk options

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=80), tidy=FALSE) 
```

## Loading packages and initializing

```{r package, message=FALSE, warning=FALSE}
library(readxl)
library(dplyr)
library(lubridate)
library(ggplot2)
library(forecast)
library(openxlsx)
library(here)
library(tseries)

```

## Import and transform load data

```{r}
#Import hourly load data
load_data <- read_excel("data/load.xlsx")

#Convert to daily average load
load_daily <- load_data %>%
  mutate(DailyLoad = rowMeans(select(., h1:h24), na.rm = TRUE)) %>%
  select(date, DailyLoad)

summary(load_daily)

#Transforming into time series objects
load_daily_ts <- msts(load_daily$DailyLoad,
                start = c(2005, 1, 1),
                seasonal.periods = c(7, 365.25))

#Plot the time series
autoplot(load_daily_ts) +
  labs(title = "Daily Electricity Load Time Series")

#Decompose daily load time series
load_daily_ts %>% mstl() %>%
  autoplot()

```

## Prepare training and test sets

```{r}
#Create a subset for training purpose from 2005-01-01 to 2009-12-31
n_for = 59

load_daily_train_ts <- subset(load_daily_ts, end = length(load_daily_ts) - n_for)

#Create a subset for testing purpose from 2010-01-01 to 2010-02-28
load_daily_test_ts   <- subset(load_daily_ts, start = length(load_daily_ts) - n_for + 1)


#Plot training and testing sets
autoplot(load_daily_train_ts)
autoplot(load_daily_test_ts)
```

## Modles:
SARIMA, ARIMA + Fourier, STL + ETS, BSM, TBATS, NNETAR

## Model 1 - Naive

```{r}
#Fit naive model to training data
naive_model <- naive(load_daily_train_ts, h = n_for)

#Plot forecast vs actual
autoplot(naive_model) +
  autolayer(load_daily_test_ts, series = "Actual", color = "red") +
  labs(title = "Naive Forecast vs Actual 2010 Janâ€“Feb",
       y = "Daily Load")

#Refit model on full dataset
naive_model_full <- naive(load_daily_ts, h = n_for)
str(naive_model_full)

#Extract forecast values
forecast_2011_model_1 <- as.numeric(naive_model_full$mean)

```

## Model 2 - STL + ETS

```{r}

ETS_fit <- stlf(load_daily_train_ts, h = n_for)

autoplot(ETS_fit) + ylab("Daily Demand")

#plot with full data
autoplot(load_daily_ts) + 
  autolayer(ETS_fit, series = "STL + ETS", PI = FALSE)

#fit on full dataset
ETS_full <- stlf(load_daily_ts, h = n_for)
str(ETS_full)

#accuracy
ETS_scores <- accuracy(ETS_fit$mean, load_daily_test_ts)

forecast_2011_model_2 <- as.numeric(ETS_full$mean)

#Read submission template
template <- read_excel("data/submission_template.xlsx")

#Insert forecast
template$load <- forecast_2011_model_2

#Save as CSV
write.csv(template, "forecasts/forecast_submission_model_2.csv", row.names = FALSE)

```

## Model 3 - ARIMA + FOURIER terms

```{r}

k = c(2,6)

ARIMA_Fourier_Fit <- auto.arima(load_daily_train_ts,
                                seasonal = FALSE,
                                lambda = 0,
                                xreg = fourier(load_daily_train_ts,
                                               K = k))

ARIMA_Fourier_Forecast <- forecast(ARIMA_Fourier_Fit,
                                   xreg = fourier(load_daily_train_ts,
                                                  K = k,
                                                  h = n_for),
                                   h = n_for)

autoplot(ARIMA_Fourier_Forecast) 

autoplot(load_daily_ts) + 
  autolayer(ARIMA_Fourier_Forecast, series = "ARIMA_FOURIER", PI = FALSE)


```

```{r}
#Fit on full dataset

ARIMA_Fourier_Fit_Full <- auto.arima(load_daily_ts,
                                seasonal = FALSE,
                                lambda = 0,
                                xreg = fourier(load_daily_ts,
                                               K = k))

ARIMA_Fourier_Forecast_Full <- forecast(ARIMA_Fourier_Fit_Full,
                                   xreg = fourier(load_daily_ts,
                                                  K = k,
                                                  h = n_for),
                                   h = n_for)

str(ARIMA_Fourier_Forecast_Full)

forecast_2011_model_3 <- as.numeric(ARIMA_Fourier_Forecast_Full$mean)

#Read submission template
template <- read_excel("data/submission_template.xlsx")

#Insert forecast
template$load <- forecast_2011_model_3

#accuracy
ARIMA_Fourier_scores <- accuracy(ARIMA_Fourier_Forecast$mean, load_daily_test_ts)

#Save as CSV
write.csv(template, "forecasts/forecast_submission_model_3.csv", row.names = FALSE)

```




## Model 4 - SARIMA


## Model 5 - TBATS

```{r}

#Fit on training data
TBATS_fit <- tbats(load_daily_train_ts)

TBATS_forecast <- forecast(TBATS_fit, h = n_for)


autoplot(TBATS_forecast) 

autoplot(load_daily_ts) + 
  autolayer(TBATS_forecast, series = "TBATS", PI = FALSE)

TBATS_scores <- accuracy(TBATS_forecast$mean, load_daily_test_ts)


#Fit on full data
TBATS_full <- tbats(load_daily_ts)
TBATS_forecast_full <- forecast(TBATS_full, h = n_for)

forecast_2011_model_5 <- as.numeric(TBATS_forecast_full$mean)

#Read submission template
template <- read_excel("data/submission_template.xlsx")

#Insert forecast
template$load <- forecast_2011_model_5

#Save as CSV
write.csv(template, "forecasts/forecast_submission_model_5.csv", row.names = FALSE)

```


## Model 6 - BSM

```{r}
#variances for level, trend, seasonal, observation

BSM_fit <- StructTS(load_daily_test_ts, type = "BSM")

checkresiduals(BSM_fit)

BSM_forecast <- forecast(BSM_fit, h = n_for)
autoplot(BSM_forecast) 

autoplot(load_daily_ts) + 
  autolayer(BSM_forecast, series = "BSM", PI = FALSE)

```


## Model 7 - NNETAR

```{r}

NN_fit <- nnetar(load_daily_train_ts,
                 p = 1,
                 P = 0,
                 xreg = fourier(load_daily_train_ts, K=c(2,12)))

NN_forecast <- forecast(NN_fit, h = n_for, 
                 xreg = fourier(load_daily_train_ts, 
                                K = c(2,12),
                                h = n_for))
checkresiduals(NN_forecast)



autoplot(NN_forecast)

autoplot(load_daily_ts) + 
  autolayer(NN_forecast, series = "NNETAR", PI = FALSE)

NN_scores <- accuracy(NN_forecast$mean, load_daily_test_ts)

```


```{r}



#Fit on full data
NN_fit_full <- nnetar(load_daily_ts,
                 p = 1,
                 P = 0,
                 xreg = fourier(load_daily_ts, K=c(2,12)))

NN_forecast_full <- forecast(NN_fit_full, h = n_for, 
                 xreg = fourier(load_daily_ts, 
                                K = c(2,12),
                                h = n_for))

forecast_2011_model_7 <- as.numeric(NN_forecast_full$mean)
#Read submission template
template <- read_excel("data/submission_template.xlsx")

#Insert forecast
template$load <- forecast_2011_model_7

#Save as CSV
write.csv(template, "forecasts/forecast_submission_model_7.csv", row.names = FALSE)
```



```{r}
grid_week <- 1:3
grid_year <- 4:15
results <- data.frame()


for (K_w in grid_week) {
  for (K_y in grid_year) {
    K_vec  <- c(K_w, K_y)
    fit    <- nnetar(load_daily_train_ts, p = 1, P = 0,
                     xreg = fourier(load_daily_train_ts, K = K_vec))
    fc     <- forecast(fit, h = n_for,
                       xreg = fourier(load_daily_train_ts, K = K_vec, h = n_for))
    rmse   <- accuracy(fc, load_daily_test_ts)["Test set", "RMSE"]
    results<- rbind(results,
                    data.frame(K_week = K_w, K_year = K_y, RMSE = rmse))
  }
}

best_K <- results[which.min(results$RMSE), c("K_week","K_year")]
print(best_K)

```


```{r}


#Fit on full data
NN_fit_full <- nnetar(load_daily_ts,
                 p = 1,
                 P = 0,
                 xreg = fourier(load_daily_ts, K=c(3,15)))

NN_forecast_full <- forecast(NN_fit_full, h = n_for, 
                 xreg = fourier(load_daily_ts, 
                                K = c(3,15),
                                h = n_for))

forecast_2011_model_8 <- as.numeric(NN_forecast_full$mean)
#Read submission template
template <- read_excel("data/submission_template.xlsx")

#Insert forecast
template$load <- forecast_2011_model_8

#Save as CSV
write.csv(template, "forecasts/forecast_submission_model_8.csv", row.names = FALSE)
```


## Scenario Generation

```{r}

temperature <- read_excel("data/temperature.xlsx")
humidity <- read_excel("data/relative_humidity.xlsx")

temperature_daily <- temperature %>% 
  group_by(date) %>% 
  summarise(across(starts_with("t_ws"),
                   ~ mean(.x, na.rm = TRUE)))

humidity_daily <- humidity %>% 
  group_by(date) %>% 
  summarise(across(starts_with("rh_ws"),
                   ~ mean(.x, na.rm = TRUE)))

data_all <- load_daily %>% 
  right_join(., temperature_daily) %>% 
  right_join(., humidity_daily)


all_data_ts <- msts(log(data_all[2:ncol(as.matrix(data_all[ , -1]))]),
                start = c(2005, 1, 1),
                seasonal.periods = c(7, 365.25))

all_data_ts <- all_data_ts[,c("DailyLoad", "t_ws1", "rh_ws1")]

R = cor(all_data_ts)

horizon <- n_for
nscen <- 10

X = array(0, c(ncol(all_data_ts), horizon, nscen))

for(i in 1:ncol(all_data_ts)){
    k = c(2,6)
    fit_SARIMA = auto.arima(all_data_ts[,i],
                          seasonal = FALSE,
                          lambda = 0,
                          xreg = fourier(all_data_ts[,i],
                          K = k))
  
    for_SARIMA=forecast(fit_SARIMA,
                      xreg = fourier(all_data_ts[,i],
                      K = k,
                      h = n_for),
                      h = n_for)   #forecast using the fitted SARIMA
  
    for(t in 1:horizon){
    # we will use the following expression to manually compute sd
    sd=(for_SARIMA$upper[t,1] - for_SARIMA$lower[t,1]) / (2 * qnorm(.5 + for_SARIMA$level[1] / 200))
    
    # Now that I have mean and standard deviation for time t
    # I can draw scenarios using the rnorm() function
    X[i,t,] <- rnorm(nscen,mean=for_SARIMA$mean[t],sd=sd)  
    
    #note this is done in a loop for all the 24 steps we are forecasting 
    #and this loop is inside a loop over all HPP inflows
    
    } # end t loop

  # remove models just to make sure we start from scratch for the next HPP
  # remember we are still inside the HPP loop
  rm(fit_SARIMA, for_SARIMA) 
                      
}

X
```


Now our array/matrix X has all the draws/scenarios but notice they don't have the same correlation we observed in the historical data.
```{r}
#Calculating correlation for s=1
aux <- X[,,1]
cor(t(aux))
```


Let's fix that with Cholesky.

```{r}
U <- chol(R) #that will give upper triangular matrix for Cholesky decomposition
L <- t(U) #to get lower triangular matrix you need to transpose U, that is what the t() function is doing here

#Creating array Y where we will store correlated scenarios
Y <- array(0,c(ncol(all_data_ts),horizon,nscen)) 

# Need to use another loop structure to make sure spatial correlation among HPP is present in all scenarios
for(s in 1:nscen){ 
  aux <- X[,,s] #creating aux variable simple because X is not a 2x2 matrix, 
                  #but an array of 3 dimension and we cannot do matrix multiplication with arrays
  
  Y[,,s] <- L%*%aux  #recall L is the Cholesky decomposition of our correlation matrix R computed from with historical data

}#end scenario loop


#Calculate correlation again
aux <- Y[,,1]
cor(t(aux))

Y
```


```{r}

#exponentiate back
for(s in 1:nscen){
  Y[,,s] <- exp(Y[,,s])
}

Y[1,,]

#getting min and max values of Y to make sure all scenarios will be within the plot limits 
ymax <- 20 # max(Y[1,,])
ymin <- 0 #min(Y[1,,])
plot(Y[1,,1],col="gray",type="l",ylim=c(ymin,ymax),xaxt='n',xlab="") #plotting first scenario
axis(1,at=c(1,13),labels=c("2011","2012"))
for(s in 2:nscen){
  lines(Y[1,,s],col="gray")   #adding lines to the plot corresponding to all scenarios
} 


```





